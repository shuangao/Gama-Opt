\relax 
\citation{tommasi2014learning}
\citation{fei2006one}
\citation{tommasi2014learning}
\citation{kuzborskij2013n}
\citation{jie2011multiclass}
\citation{Thrun96islearning}
\citation{kuzborskij2013n}
\citation{Lu201514}
\citation{tommasi2014learning}
\citation{kuzborskij2013n}
\citation{yang2007cross}
\citation{aytar2011tabula}
\citation{suykens1999least}
\citation{kuzborskij2013stability}
\citation{cawley2006leave}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Positive transfer VS Negative transfer. Relying on unrelated prior knowledge too much could lead to negative transfer.\relax }}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:neg}{{1}{1}}
\citation{pan2010survey}
\citation{tommasi2014learning}
\citation{lim2012transfer}
\citation{LongICML15}
\citation{yang2007cross}
\citation{aytar2011tabula}
\citation{tommasi2014learning}
\citation{kuzborskij2013n}
\citation{davis2009deep}
\citation{wang2014active}
\citation{zhou2014multi}
\citation{kuzborskij2013n}
\citation{tommasi2010safety}
\citation{cawley2006leave}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Negative transfer happens when we transfer prior knowledge $f'$ to target one. Points with different color represent different categories. The data distribution would change even for identical categories in different task. The new added category (red points) can greatly affect the data distribution in target task. \relax }}{2}}
\newlabel{fig:distribution}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Works}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Problem Statement}{2}}
\citation{yang2007cross}
\citation{tommasi2014learning}
\citation{tommasi2014learning}
\citation{kuzborskij2013n}
\citation{cawley2006leave}
\citation{crammer2002algorithmic}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}LS-SVM Setting and Definition}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces useful notations in this paper\relax }}{3}}
\newlabel{tab:notation}{{I}{3}}
\newlabel{eq:linear}{{1}{3}}
\newlabel{eq:opt}{{2}{3}}
\newlabel{eq:solution}{{4}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Optimize $\gamma $ and $\beta $}{3}}
\citation{BoydCO}
\citation{shalev2011pegasos}
\newlabel{eq:train_loss}{{6}{4}}
\newlabel{loss}{{7}{4}}
\newlabel{eq:dual}{{8}{4}}
\newlabel{alg:1}{{\caption@xref {alg:1}{ on input line 1}}{4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces $\gamma $ optimization\relax }}{4}}
\newlabel{alg:1}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Analysis}{4}}
\newlabel{subsec:analysis}{{\unhbox \voidb@x \hbox {III-C}}{4}}
\newlabel{th:1}{{1}{4}}
\citation{lampert2009learning}
\citation{griffin2007caltech}
\newlabel{eq:loss_simple}{{10}{5}}
\newlabel{eq:opt_gama}{{11}{5}}
\newlabel{eq:opt_beta}{{12}{5}}
\newlabel{eq:link1}{{13}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiment}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Dataset}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Baselines and algorithmic setup}{5}}
\citation{jie2011multiclass}
\citation{tommasi2014learning}
\citation{kuzborskij2013n}
\citation{gehler2009feature}
\bibstyle{IEEEtran}
\bibdata{research}
\bibcite{tommasi2014learning}{1}
\bibcite{fei2006one}{2}
\bibcite{kuzborskij2013n}{3}
\bibcite{jie2011multiclass}{4}
\bibcite{Thrun96islearning}{5}
\bibcite{Lu201514}{6}
\bibcite{yang2007cross}{7}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Positive Transfer}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Overall Caltech to Caltech with different size of training set in target problem. 30 examples are randomly chosen from each class to train the source classifier and 30 examples from each class are chosen for test. \relax }}{6}}
\newlabel{tab:C2C}{{II}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Overall AwA to AwA with different size of training set in target problem. 50 examples are randomly chosen from each class to train the source classifier and 200 examples from each class are chosen for test.\relax }}{6}}
\newlabel{tab:A2A}{{III}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}from bad oracle}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-E}}mixed}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{6}}
\@writefile{toc}{\contentsline {section}{References}{6}}
\newlabel{fig:awa-a}{{3a}{7}}
\newlabel{sub@fig:awa-a}{{(a)}{a}}
\newlabel{fig:awa-b}{{3b}{7}}
\newlabel{sub@fig:awa-b}{{(b)}{b}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Experiment results for 10 classes, AwA. Horse is used as the new category. \subref {fig:awa-a}\relax }}{7}}
\newlabel{fig:awa}{{3}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Overall accuracy comparision with different baselines. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Comparision with MULTIpLE.}}}{7}}
\newlabel{fig:a2c-a}{{4a}{7}}
\newlabel{sub@fig:a2c-a}{{(a)}{a}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Experiment results for 10 classes, AwA. Horse is used as the new category. \subref {fig:a2c-a}\relax }}{7}}
\newlabel{fig:a2c}{{4}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Overall accuracy comparision with different baselines. }}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Comparision with MULTIpLE.}}}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Overall AwA to Caltech\relax }}{7}}
\newlabel{tab:addlabel}{{IV}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces AwA leave class 6 as new category. 2345 as bad class\relax }}{7}}
\bibcite{aytar2011tabula}{8}
\bibcite{suykens1999least}{9}
\bibcite{kuzborskij2013stability}{10}
\bibcite{cawley2006leave}{11}
\bibcite{pan2010survey}{12}
\bibcite{lim2012transfer}{13}
\bibcite{LongICML15}{14}
\bibcite{davis2009deep}{15}
\bibcite{wang2014active}{16}
\bibcite{zhou2014multi}{17}
\bibcite{tommasi2010safety}{18}
\bibcite{crammer2002algorithmic}{19}
\bibcite{BoydCO}{20}
\bibcite{shalev2011pegasos}{21}
\bibcite{lampert2009learning}{22}
\bibcite{griffin2007caltech}{23}
\bibcite{gehler2009feature}{24}
